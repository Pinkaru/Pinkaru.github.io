---
title: "ë¶„ì‚° IPC - ë¡œì»¬ì—ì„œ ë„¤íŠ¸ì›Œí¬ë¡œ"
date: 2025-02-06
tags: [IPC, Distributed Systems, gRPC, ZeroMQ, Network, Migration]
description: "ë¡œì»¬ IPCë¥¼ ë„¤íŠ¸ì›Œí¬ IPCë¡œ í™•ì¥í•˜ëŠ” ì „ëµ, gRPCì™€ ZeroMQ í™œìš©ë²•, í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."
---

## ë“¤ì–´ê°€ë©°

ì‹œìŠ¤í…œì´ ì„±ì¥í•˜ë©´ **ë‹¨ì¼ ì„œë²„**ì—ì„œ **ë¶„ì‚° ì‹œìŠ¤í…œ**ìœ¼ë¡œ ì „í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¡œì»¬ IPCë¥¼ ë„¤íŠ¸ì›Œí¬ IPCë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ì „ëµê³¼ ë„êµ¬ë¥¼ ë°°ì›ë‹ˆë‹¤.

## ì–¸ì œ ë¶„ì‚° IPCê°€ í•„ìš”í•œê°€?

### ì „í™˜ ì‹œì 

```mermaid
graph TB
    Start{í˜„ì¬ ìƒí™©}

    Start -->|ë‹¨ì¼ ì„œë²„| Local[ë¡œì»¬ IPC]
    Start -->|ì—¬ëŸ¬ ì„œë²„| Distributed[ë¶„ì‚° IPC]

    Local --> Trigger{íŠ¸ë¦¬ê±°}

    Trigger -->|í™•ì¥ì„± í•œê³„| T1[CPU/ë©”ëª¨ë¦¬ ë¶€ì¡±]
    Trigger -->|ê°€ìš©ì„±| T2[ë‹¨ì¼ ì¥ì• ì ]
    Trigger -->|ì§€ì—­ ë¶„ì‚°| T3[ë‹¤ë¥¸ ë°ì´í„°ì„¼í„°]
    Trigger -->|ì„œë¹„ìŠ¤ ë¶„ë¦¬| T4[ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤]

    T1 --> Distributed
    T2 --> Distributed
    T3 --> Distributed
    T4 --> Distributed

    style Distributed fill:#c8e6c9,stroke:#388e3c
```

### ë¹„êµ

| í•­ëª© | ë¡œì»¬ IPC | ë„¤íŠ¸ì›Œí¬ IPC |
|------|----------|-------------|
| **ë ˆì´í„´ì‹œ** | 1-10 Î¼s | 0.1-10 ms |
| **ëŒ€ì—­í­** | 10+ GB/s | 1-10 GB/s |
| **ì‹ ë¢°ì„±** | ë§¤ìš° ë†’ìŒ | ì¤‘ê°„ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜) |
| **ë³µì¡ë„** | ë‚®ìŒ | ë†’ìŒ |
| **í™•ì¥ì„±** | ì œí•œì  | ë¬´í•œ |
| **ì¥ì•  ê²©ë¦¬** | ì—†ìŒ | ìˆìŒ |

## ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### ë‹¨ê³„ë³„ ì ‘ê·¼

```mermaid
graph LR
    Phase1[Phase 1<br/>ì¶”ìƒí™” ê³„ì¸µ]
    Phase2[Phase 2<br/>í•˜ì´ë¸Œë¦¬ë“œ]
    Phase3[Phase 3<br/>ì™„ì „ ë¶„ì‚°]

    Phase1 -->|ì ì§„ì | Phase2
    Phase2 -->|ì ì§„ì | Phase3

    style Phase1 fill:#e1f5ff,stroke:#0288d1
    style Phase2 fill:#fff9c4,stroke:#f57f17
    style Phase3 fill:#c8e6c9,stroke:#388e3c
```

### 1ë‹¨ê³„: ì¶”ìƒí™” ê³„ì¸µ

```c
// ipc_abstraction.h
typedef enum {
    IPC_LOCAL,    // Unix Socket
    IPC_NETWORK   // TCP Socket
} ipc_mode_t;

typedef struct {
    ipc_mode_t mode;
    int fd;
    // ì—°ê²° ì •ë³´...
} ipc_conn_t;

// í†µí•© API
ipc_conn_t* ipc_connect(const char *address);
int ipc_send(ipc_conn_t *conn, const void *data, size_t len);
int ipc_recv(ipc_conn_t *conn, void *data, size_t len);
void ipc_close(ipc_conn_t *conn);
```

```c
// ipc_abstraction.c
#include <string.h>
#include <sys/socket.h>
#include <sys/un.h>
#include <arpa/inet.h>

ipc_conn_t* ipc_connect(const char *address) {
    ipc_conn_t *conn = malloc(sizeof(ipc_conn_t));

    // "unix:///tmp/socket" or "tcp://host:port"
    if (strncmp(address, "unix://", 7) == 0) {
        conn->mode = IPC_LOCAL;
        conn->fd = socket(AF_UNIX, SOCK_STREAM, 0);

        struct sockaddr_un addr = {0};
        addr.sun_family = AF_UNIX;
        strncpy(addr.sun_path, address + 7, sizeof(addr.sun_path) - 1);

        connect(conn->fd, (struct sockaddr*)&addr, sizeof(addr));

    } else if (strncmp(address, "tcp://", 6) == 0) {
        conn->mode = IPC_NETWORK;
        conn->fd = socket(AF_INET, SOCK_STREAM, 0);

        // host:port íŒŒì‹±
        char *host_port = strdup(address + 6);
        char *colon = strchr(host_port, ':');
        *colon = '\0';
        char *host = host_port;
        int port = atoi(colon + 1);

        struct sockaddr_in addr = {0};
        addr.sin_family = AF_INET;
        addr.sin_port = htons(port);
        inet_pton(AF_INET, host, &addr.sin_addr);

        connect(conn->fd, (struct sockaddr*)&addr, sizeof(addr));

        free(host_port);
    }

    return conn;
}

int ipc_send(ipc_conn_t *conn, const void *data, size_t len) {
    return send(conn->fd, data, len, 0);
}

int ipc_recv(ipc_conn_t *conn, void *data, size_t len) {
    return recv(conn->fd, data, len, 0);
}

void ipc_close(ipc_conn_t *conn) {
    close(conn->fd);
    free(conn);
}
```

### ì‚¬ìš© ì˜ˆì œ

```c
// application.c
int main() {
    // í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì •ìœ¼ë¡œ ì „í™˜ ê°€ëŠ¥
    const char *endpoint = getenv("IPC_ENDPOINT");
    if (!endpoint) {
        endpoint = "unix:///tmp/myapp";  // ê¸°ë³¸: ë¡œì»¬
        // endpoint = "tcp://10.0.0.5:8080";  // ë¶„ì‚°
    }

    ipc_conn_t *conn = ipc_connect(endpoint);

    // ë™ì¼í•œ ì½”ë“œë¡œ ë¡œì»¬/ë„¤íŠ¸ì›Œí¬ ëª¨ë‘ ì§€ì›
    char *message = "Hello";
    ipc_send(conn, message, strlen(message));

    char buffer[1024];
    ipc_recv(conn, buffer, sizeof(buffer));

    ipc_close(conn);
    return 0;
}
```

## gRPC - í˜„ëŒ€ì  ë¶„ì‚° IPC

### ê°œë…

```mermaid
graph LR
    Client[Client<br/>Any Language]
    gRPC[gRPC Framework<br/>HTTP/2 + Protobuf]
    Server[Server<br/>Any Language]

    Client -->|Request| gRPC
    gRPC -->|Protobuf| Server
    Server -->|Response| gRPC
    gRPC -->|Protobuf| Client

    style gRPC fill:#c8e6c9,stroke:#388e3c
```

### ì •ì˜ íŒŒì¼

```protobuf
// calculator.proto
syntax = "proto3";

service Calculator {
    rpc Add (AddRequest) returns (AddResponse);
    rpc StreamData (stream DataRequest) returns (stream DataResponse);
}

message AddRequest {
    int32 a = 1;
    int32 b = 2;
}

message AddResponse {
    int32 result = 1;
}

message DataRequest {
    int32 id = 1;
}

message DataResponse {
    int32 id = 1;
    string data = 2;
}
```

### Python ì„œë²„

```python
# grpc_server.py
import grpc
from concurrent import futures
import calculator_pb2
import calculator_pb2_grpc

class CalculatorServicer(calculator_pb2_grpc.CalculatorServicer):
    def Add(self, request, context):
        result = request.a + request.b
        return calculator_pb2.AddResponse(result=result)

    def StreamData(self, request_iterator, context):
        for request in request_iterator:
            yield calculator_pb2.DataResponse(
                id=request.id,
                data=f"Processed {request.id}"
            )

def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    calculator_pb2_grpc.add_CalculatorServicer_to_server(
        CalculatorServicer(), server
    )
    server.add_insecure_port('[::]:50051')
    server.start()
    print("gRPC server listening on port 50051")
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
```

### C++ í´ë¼ì´ì–¸íŠ¸

```cpp
// grpc_client.cpp
#include <grpcpp/grpcpp.h>
#include "calculator.grpc.pb.h"

using grpc::Channel;
using grpc::ClientContext;
using grpc::Status;

class CalculatorClient {
public:
    CalculatorClient(std::shared_ptr<Channel> channel)
        : stub_(Calculator::NewStub(channel)) {}

    int Add(int a, int b) {
        AddRequest request;
        request.set_a(a);
        request.set_b(b);

        AddResponse response;
        ClientContext context;

        Status status = stub_->Add(&context, request, &response);

        if (status.ok()) {
            return response.result();
        } else {
            std::cerr << "RPC failed" << std::endl;
            return -1;
        }
    }

private:
    std::unique_ptr<Calculator::Stub> stub_;
};

int main() {
    CalculatorClient client(
        grpc::CreateChannel("localhost:50051",
                           grpc::InsecureChannelCredentials())
    );

    int result = client.Add(10, 20);
    std::cout << "10 + 20 = " << result << std::endl;

    return 0;
}
```

## ZeroMQ - ë©”ì‹œì§€ í ë¼ì´ë¸ŒëŸ¬ë¦¬

### Request-Reply íŒ¨í„´

```python
# zmq_server.py
import zmq

context = zmq.Context()
socket = context.socket(zmq.REP)  # Reply
socket.bind("tcp://*:5555")

print("ZeroMQ server listening on port 5555")

while True:
    message = socket.recv_string()
    print(f"Received: {message}")

    response = f"Echo: {message}"
    socket.send_string(response)
```

```c
// zmq_client.c
#include <zmq.h>
#include <string.h>
#include <stdio.h>

int main() {
    void *context = zmq_ctx_new();
    void *socket = zmq_socket(context, ZMQ_REQ);  // Request

    zmq_connect(socket, "tcp://localhost:5555");

    const char *message = "Hello ZeroMQ";
    zmq_send(socket, message, strlen(message), 0);

    char buffer[256];
    int size = zmq_recv(socket, buffer, sizeof(buffer) - 1, 0);
    buffer[size] = '\0';

    printf("Received: %s\n", buffer);

    zmq_close(socket);
    zmq_ctx_destroy(context);

    return 0;
}
```

### Publish-Subscribe íŒ¨í„´

```python
# zmq_publisher.py
import zmq
import time

context = zmq.Context()
socket = context.socket(zmq.PUB)  # Publisher
socket.bind("tcp://*:5556")

topic = "weather"

while True:
    message = f"{topic} temperature:25"
    socket.send_string(message)
    print(f"Published: {message}")
    time.sleep(1)
```

```python
# zmq_subscriber.py
import zmq

context = zmq.Context()
socket = context.socket(zmq.SUB)  # Subscriber
socket.connect("tcp://localhost:5556")

# í† í”½ í•„í„°
socket.setsockopt_string(zmq.SUBSCRIBE, "weather")

while True:
    message = socket.recv_string()
    print(f"Received: {message}")
```

## í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜

### ë¡œì»¬ + ë„¤íŠ¸ì›Œí¬ í˜¼í•©

```mermaid
graph TB
    subgraph "Server 1"
        App1[App 1]
        App2[App 2]
        LocalIPC[Unix Socket<br/>ë¡œì»¬ ê³ ì† í†µì‹ ]

        App1 <-->|Local IPC| LocalIPC
        App2 <-->|Local IPC| LocalIPC
    end

    subgraph "Server 2"
        App3[App 3]
        App4[App 4]
        LocalIPC2[Unix Socket]

        App3 <-->|Local IPC| LocalIPC2
        App4 <-->|Local IPC| LocalIPC2
    end

    Gateway1[Gateway]
    Gateway2[Gateway]

    LocalIPC <--> Gateway1
    LocalIPC2 <--> Gateway2

    Gateway1 <-->|gRPC/TCP| Gateway2

    style LocalIPC fill:#c8e6c9,stroke:#388e3c
    style Gateway1 fill:#fff9c4,stroke:#f57f17
```

### êµ¬í˜„

```c
// hybrid_gateway.c
// Unix Socketìœ¼ë¡œ ë¡œì»¬ ì•± ìˆ˜ì‹ , TCPë¡œ ë‹¤ë¥¸ ì„œë²„ ì „ì†¡

void local_handler() {
    // Unix Socket ì„œë²„
    int local_fd = socket(AF_UNIX, SOCK_STREAM, 0);
    // ... bind, listen ...

    while (1) {
        int client_fd = accept(local_fd, NULL, NULL);

        // ë¡œì»¬ í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ìˆ˜ì‹ 
        char buffer[1024];
        read(client_fd, buffer, sizeof(buffer));

        // ë‹¤ë¥¸ ì„œë²„ë¡œ ì „ì†¡ (TCP)
        forward_to_remote(buffer);

        close(client_fd);
    }
}

void forward_to_remote(const char *data) {
    int tcp_fd = socket(AF_INET, SOCK_STREAM, 0);
    // ... connect to remote server ...

    send(tcp_fd, data, strlen(data), 0);

    close(tcp_fd);
}
```

## ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### ë ˆì´í„´ì‹œ ë¹„êµ

```mermaid
graph LR
    subgraph "ë ˆì´í„´ì‹œ (P99)"
        L1[Unix Socket<br/>10 Î¼s]
        L2[TCP Loopback<br/>100 Î¼s]
        L3[ê°™ì€ ë°ì´í„°ì„¼í„°<br/>0.5 ms]
        L4[ë‹¤ë¥¸ ë°ì´í„°ì„¼í„°<br/>50 ms]
    end

    style L1 fill:#c8e6c9,stroke:#388e3c
    style L4 fill:#ffccbc,stroke:#d84315
```

### ìµœì í™” ì „ëµ

```python
# 1. ì—°ê²° í’€ ì‚¬ìš©
import grpc

channel = grpc.insecure_channel(
    'server:50051',
    options=[
        ('grpc.max_receive_message_length', 100 * 1024 * 1024),
        ('grpc.keepalive_time_ms', 10000),
        ('grpc.http2.max_pings_without_data', 0)
    ]
)

# 2. Batch ì²˜ë¦¬
requests = [req1, req2, req3, ...]
responses = stub.BatchProcess(iter(requests))

# 3. ì••ì¶•
channel = grpc.insecure_channel(
    'server:50051',
    compression=grpc.Compression.Gzip
)
```

## ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„

### ì¬ì‹œë„ ì •ì±…

```python
# grpc_retry.py
import grpc
from grpc._channel import _InactiveRpcError

def call_with_retry(stub, request, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = stub.SomeMethod(request, timeout=5.0)
            return response

        except grpc.RpcError as e:
            if e.code() == grpc.StatusCode.UNAVAILABLE:
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # Exponential backoff
                    continue
                else:
                    raise

            elif e.code() == grpc.StatusCode.DEADLINE_EXCEEDED:
                print("Timeout, retrying...")
                continue

            else:
                raise  # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì „íŒŒ
```

## ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ì„±

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```python
# monitoring.py
from prometheus_client import Counter, Histogram
import time

# ë©”íŠ¸ë¦­ ì •ì˜
request_count = Counter('ipc_requests_total', 'Total IPC requests')
request_latency = Histogram('ipc_request_latency_seconds', 'IPC request latency')

def monitored_rpc_call(stub, request):
    request_count.inc()

    start = time.time()
    try:
        response = stub.Call(request)
        return response
    finally:
        duration = time.time() - start
        request_latency.observe(duration)
```

## ì„ íƒ ê°€ì´ë“œ

### ì˜ì‚¬ê²°ì • íŠ¸ë¦¬

```mermaid
graph TD
    Start{ì‚¬ìš© ì‚¬ë¡€}

    Start -->|ë†’ì€ ì„±ëŠ¥<br/>ë‚®ì€ ë ˆì´í„´ì‹œ| Local[Unix Socket]
    Start -->|ë¶„ì‚° í•„ìš”| Q1

    Q1{ì–¸ì–´}
    Q1 -->|ë‹¤ì–‘í•œ ì–¸ì–´| gRPC[gRPC]
    Q1 -->|C/C++ ìœ„ì£¼| ZMQ

    Q1 -->|ë³µì¡í•œ íŒ¨í„´| Q2

    Q2{íŒ¨í„´}
    Q2 -->|Request-Reply| gRPC2[gRPC/ZMQ]
    Q2 -->|Pub-Sub| ZMQ2[ZeroMQ]
    Q2 -->|Push-Pull| ZMQ3[ZeroMQ]

    style Local fill:#c8e6c9,stroke:#388e3c
    style gRPC fill:#e1f5ff,stroke:#0288d1
    style ZMQ fill:#fff9c4,stroke:#f57f17
```

## ë‹¤ìŒ ë‹¨ê³„

ë¶„ì‚° IPCë¥¼ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤! ë‹¤ìŒ ê¸€ì—ì„œëŠ”:
- **IPC ì‹¤ì „ ì˜ˆì œ** - Chrome, systemd, PostgreSQL ì‚¬ë¡€ ì—°êµ¬
- ì‹¤ì œ ì‹œìŠ¤í…œ ë¶„ì„
- ì„¤ê³„ íŒ¨í„´ ì¶”ì¶œ

---

**ì‹œë¦¬ì¦ˆ ëª©ì°¨**
18. **ë¶„ì‚° IPC** â† í˜„ì¬ ê¸€
19. IPC ì‹¤ì „ ì˜ˆì œ (ë‹¤ìŒ ê¸€)

> ğŸ’¡ **Quick Tip**: ë¡œì»¬ í†µì‹ ì€ Unix Socket, ê°™ì€ ë°ì´í„°ì„¼í„°ëŠ” gRPC, ë³µì¡í•œ íŒ¨í„´ì€ ZeroMQë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ì¶”ìƒí™” ê³„ì¸µì„ ë§Œë“¤ì–´ ìœ ì—°í•˜ê²Œ ì „í™˜ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„í•˜ì„¸ìš”!
